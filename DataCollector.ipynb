{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VicAID: Sistema Autonómo de Conducción Basado en Redes Neuronales Convolucionales de Profundidad\n",
    "Autores:G. Alarcón, D. Lajo\n",
    "\n",
    "VicAID es un programa de conducción vehicular autónoma basado en técnicas de machine learning. Como primera instancia de investigación, se desea emular la capacidad de manejo a través de un simulador de conducción (TORCS).\n",
    "\n",
    "Esta primera instancia concidera las siguientes características:\n",
    "* La data de entrenamiento se recolectara a partir de un programa que grabara las acciones realizadas por un usuario humano interactuando con TORCS.\n",
    "* La velocidad dentro de TORCS será constante (caja de cambios en primera).\n",
    "* Las acciones de interes serán los giros del volante (derecha/izquierda/sin acción).\n",
    "* El programa recolector ejecutara un video capturador en la ventana de TORCS, recopilando y marcando frames con la acción ejecutada en ese momento (derecha/izquierda/sin acción).\n",
    "* EL nucleo de VicAID se entrenara a partir de la información recolectada, lo que quiere decir que, el máximo performance posible será el que el conductor humano pueda desempeñar.\n",
    "* Luego de que el entrenamiento haya alcanzado un porcentanje de precisión superior al 98%, cargaremos los valores optimizados en el programa principal de VicAID.\n",
    "\n",
    "Para llevar a cabo esta tarea, es necesario seguir el siguiente orden de trabajo:\n",
    "* Recolección de data\n",
    "    * Programa recolector\n",
    "        * Python 2.7\n",
    "        * Numpy\n",
    "        * PyAutoGUI\n",
    "        * OpenCV 3.1.0       \n",
    "* Preparación de data (ordenar y clasificar)\n",
    "* Entrenamiento VicAID\n",
    "    * Programa Entrenador\n",
    "        * Python 2.7\n",
    "        * Numpy\n",
    "        * TensorFlow\n",
    "        * IPython\n",
    "        * Sci-kit Learn\n",
    "        * Matplotlib\n",
    "    * Programa Evaluador de Entrenamiento\n",
    "* Pruebas de conducción\n",
    "    * Programa interfaz VicAID/TORCS\n",
    "        * Python 2.7\n",
    "        * Numpy\n",
    "        * TensorFlow\n",
    "        * Sci-kit Learn\n",
    "        * OpenCV 3.1.0\n",
    "        * PyAutoGUI\n",
    "* Evaluación de Rendimiento\n",
    "* Conclusiones\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El programa recolector de data esta basado en el capitulo 18 del libro \"AUTOMATE THE BORING STUFF WITH PYTHON\"\n",
    "\n",
    "Para simular/capturar el estado del teclado y mouse, utilizaremos:\n",
    "* PyAutoGUI\n",
    "\n",
    "Para ayudarnos a mostrar y guardar los frames de la ventana capturada, utilizaremos:\n",
    "* OpenCV 3.1.0\n",
    "\n",
    "Para ayudarnos a convertir los screenshots tomados con pyautogui de PILLOW a Numpy arrays, utilizaremos:\n",
    "* Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAUSE & FAIL-SAFES\n",
    "\n",
    "Para evitar problemas con bucles infinitos o estados no previstos, podemos decirle a nuestro codigo que espere unos segundos antes de cada funcion, dandonos una pequeña ventana de tiempo para tomar el control del mouse y teclado si es que algo sale mal.\n",
    "\n",
    "Para hacer esto, podemos configurar la variable \"pyautogui.PAUSE\" con elnumero de segundos que queremos que espere antes de cada funcion.\n",
    "\n",
    "PyAutoGUI, con la caracteristica FAIL-SAFE. Moviendo el mouse hacia la esquina izquierda superior, podemos invocar la excepcion \"pyautogui.FailSafeException\"\n",
    "\n",
    "Otra forma de utilizar esta caracteristica, es habilitando \"pyautogui.FAILSAFE\" en True o False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyautogui.FAILSALE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para conocer las dimensiones de la pantalla que se desea controlar, podemos utilizar la siguiente funcion \"pyautogui.size()\" y guardar el resultado en las variables width y height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080)\n"
     ]
    }
   ],
   "source": [
    "width, height = pyautogui.size()\n",
    "print(width,height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moviendo el mouse\n",
    "\n",
    "La resolucion que se utilizara en TORCS es de 1024x768 pixeles, lo que resulta en tener que trasladar el mouse al borde de la ventana de TORCS y hacer click para mantener el FOCUS de las teclas.\n",
    "\n",
    "Para esto, podemos utilizar la funcion \"pyautogui.moveTo(x,y,duration=?)\".\n",
    "\n",
    "x: x pos, y: y pos, duration: Tiempo que demora en moverse desde la posicion actual a la destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyautogui.moveTo(150,35,duration=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haciendo Click\n",
    "\n",
    "Para enviar un click virtual a la computadora, utilizamos el metodo \"pyautogui.click()\". Por defecto, este metodo usa el boton izqueirdo del mouse y se ejecuta en donde el mouse se encuentre.\n",
    "\n",
    "Para especificar la posicion y el boton que se quiere utilizar, el motodo varia al siguiente \"pyautogui.click(x,y,button=?)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyautogui.click(150,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    img = pyautogui.screenshot(region=(550,350,200,200))\n",
    "    np_image = np.array(img)\n",
    "    cv2.imshow(\"image\", np_image)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
